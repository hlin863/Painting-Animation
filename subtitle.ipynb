{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ¬ 1. Extract Audio from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: speechrecognition in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from moviepy) (2.19.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from moviepy) (1.23.4)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from moviepy) (0.4.7)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from moviepy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from moviepy) (2.32.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from speechrecognition) (4.12.2)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\haoch\\desktop\\painting-animation\\sadtalker\\venv\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install moviepy speechrecognition pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in Subtitle-Video/temp_audio/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "video = VideoFileClip(\"Subtitle-Video/video/Demo-Original.mp4\")\n",
    "video.audio.write_audiofile(\"Subtitle-Video/temp_audio/temp_audio.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  2. Transcribe Audio to Text (Speech Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "sound = AudioSegment.from_wav(\"Subtitle-Video/temp_audio/temp_audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_on_silence(sound, min_silence_len=700, silence_thresh=sound.dBFS-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles = []\n",
    "start_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, chunk in enumerate(chunks):\n",
    "#     chunk_silent = AudioSegment.silent(duration=500)\n",
    "#     audio_chunk = chunk_silent + chunk + chunk_silent\n",
    "#     chunk_filename = f\"Subtitle-Video/temp_audio/chunk{i}.wav\"\n",
    "#     audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "\n",
    "#     with sr.AudioFile(chunk_filename) as source:\n",
    "#         audio = recognizer.record(source)\n",
    "#         try:\n",
    "#             text = recognizer.recognize_google(audio)\n",
    "#             end_time = start_time + len(audio_chunk) / 1000.0\n",
    "#             subtitles.append((start_time, end_time, text))\n",
    "#             start_time = end_time\n",
    "#         except sr.UnknownValueError:\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.silence import detect_nonsilent\n",
    "import os\n",
    "\n",
    "nonsilent_ranges = detect_nonsilent(sound, min_silence_len=700, silence_thresh=sound.dBFS - 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (start_ms, end_ms) in enumerate(nonsilent_ranges):\n",
    "    chunk = sound[start_ms:end_ms]\n",
    "    chunk_filename = f\"Subtitle-Video/temp_audio/chunk{i}.wav\"\n",
    "    chunk.export(chunk_filename, format=\"wav\")\n",
    "\n",
    "    with sr.AudioFile(chunk_filename) as source:\n",
    "        audio = recognizer.record(source)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            start_time = start_ms / 1000.0\n",
    "            end_time = end_ms / 1000.0\n",
    "            subtitles.append((start_time, end_time, text))\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "\n",
    "    os.remove(chunk_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¬ 3. Burn Subtitles into Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import TextClip, CompositeVideoClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import moviepy.config as mpy_config\n",
    "# mpy_config.change_settings({\"IMAGEMAGICK_BINARY\": r\"C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\convert.exe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.config import change_settings\n",
    "change_settings({\"IMAGEMAGICK_BINARY\": r\"C:\\\\Program Files\\\\ImageMagick-7.1.1-Q16-HDRI\\\\magick.exe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import TextClip\n",
    "# solution to MoviePy not found error: https://stackoverflow.com/questions/51928807/moviepy-cant-detect-imagemagick-binary-on-windows\n",
    "\n",
    "clip = TextClip(\"Hello, world!\", fontsize=70, color='white', bg_color='black')\n",
    "clip.save_frame(\"test_output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_text(text, max_words=8):\n",
    "    \"\"\"Split a sentence into smaller chunks with up to `max_words` each.\"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+max_words]) for i in range(0, len(words), max_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitle_clips = []\n",
    "for start, end, text in subtitles:\n",
    "    duration = end - start\n",
    "    chunks = split_text(text, max_words=8)\n",
    "    chunk_duration = duration / len(chunks)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        wrapped_text = textwrap.fill(chunk, width=50)\n",
    "        txt_clip = TextClip(\n",
    "            wrapped_text,\n",
    "            fontsize=28,\n",
    "            color='white',\n",
    "            method='caption',\n",
    "            size=(int(video.w * 0.9), None)\n",
    "        )\n",
    "\n",
    "        txt_clip = txt_clip.on_color(\n",
    "            size=txt_clip.size,\n",
    "            color=(0, 0, 0),\n",
    "            col_opacity=0.6\n",
    "        )\n",
    "\n",
    "        txt_clip = txt_clip.set_position((\"center\", \"bottom\"))\n",
    "        txt_clip = txt_clip.set_start(start + i * chunk_duration).set_duration(chunk_duration)\n",
    "\n",
    "        subtitle_clips.append(txt_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video Subtitle-Video/output/Output-Demo.mp4.\n",
      "MoviePy - Writing audio in Output-DemoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video Subtitle-Video/output/Output-Demo.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Subtitle-Video/output/Output-Demo.mp4\n"
     ]
    }
   ],
   "source": [
    "final_video = CompositeVideoClip([video] + subtitle_clips, size=video.size)\n",
    "final_video.write_videofile(\"Subtitle-Video/output/Output-Demo.mp4\", codec=\"libx264\", fps=video.fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
